{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b050564-f888-4322-a878-fd14b67c9b7b",
   "metadata": {},
   "source": [
    "# 评估指标与评分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7b7dec-3eb3-4535-aa2c-a53ce75292f3",
   "metadata": {},
   "source": [
    "到目前为止，我们使用精度(正确分类的样本所占的比例)来评估分类性能，使用R^2来评估回归性能。但是，总结监督模型在给定数据集上的表现行多种方法,这两个指标只是 其中两种。在实践中，这些评估指标可能不适用于你的应用。在选择模型与调参时，选择 正确的指标是很重要的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84fc58d-54fa-47d6-882d-bc1ea4603db5",
   "metadata": {},
   "source": [
    "## 1.牢记最终目标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a0869e-1700-4594-b3f3-93c7a6d55351",
   "metadata": {},
   "source": [
    "在选择指标时，你应该始终牢记机器学习应用的最终目标。在实践中，我们通常不仅对精确的预测感兴趣，还希望将这些预测结果用于更大的决策过程。在选择机器学习指标之前，你应该考虑应用的高级目标，这通常被称为**商业指标**(business metric)。对于一个机器学习应用，选择特定算法的结果被称为**商业影响**(business impact)，高级目标可能是避 免交通事故或者减少入院人数，也可能是吸引更多的网站用户或者让用户在你的商店中花更多的钱。在选择模型或调参时，你应该选择对商业指标具有最大正面影响的模型或参数值。这通常是很难的，因为要想评估某个模型的商业影响.可能需要将它放在真实的生产环境中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc34b60-f922-4808-b2a5-8a75f6634e84",
   "metadata": {},
   "source": [
    "开发的初期阶段调参，仅为了测试就将模型投入生产环境往往是不可行的，因为可能涉及很高的商业风险或个人风险。想象一下，为了测试无人驾驶汽车的行人避让能力，没有事先验证就让它直接上路。如果模型很糟糕的话，行人就会遇到麻烦！因此，我们通常需要找到某种替代的评估程序，使用一种更容易计算的评估指标。例如，我们可以测试对行人和非行人的图片进行分类并测量精度。清记住，这只是一种替代方法，找到与原始商业目标最接近的可评估的指标也很有用。应尽可能使用这个最接近的指标来进行模型评估与选择。评估的结果可能不是一个数字—— 算法的结果可能是顾客多了 10% ,但每位顾客的花费减少了 15%，—— 但它应该给出选择一个模型而不选另一个所造成的预期商业影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08b4d8-42a6-41f7-b608-0aac2fed2dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f6526-abb2-4950-8f9b-845fa799488b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3661c314-7841-4524-ac35-14ace90b8b0e",
   "metadata": {},
   "source": [
    "##  2. 二分类指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d84fb6-3170-4fa6-b276-80582bd3c17b",
   "metadata": {},
   "source": [
    "分类可能是实践中最常见的机器学习应用，也是概念最简单的应用。但是，即使是评估这个简单任务也仍行一些注意事项.在深入研究替代指标之前,我们先看测量精度可能会如何误导我们。对于二分类问题.我们通常会说**正类**(positive class)和**反类**(negative class)，而正类是我们要寻找的类。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60817ad1-72bb-4f01-a758-bfb165a5fcfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7389b216-ac14-4e0d-aea6-ab52c0b409d2",
   "metadata": {},
   "source": [
    "### 1 .错误类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ccbec0-4149-491f-bbaa-b9708f60b7ea",
   "metadata": {},
   "source": [
    "通常来说，精度并不能很好地度量预测性能，因为我们所犯错误的数量并不包含我们感兴趣的所有信息。想象一个应用.利用自动化测来筛查癌症的早期发现，如果测试结果为阴性，那么认为患者是健康的,而如果测试结果为阳性,患者则需要接受额外的筛查，这里我们将阳性测试结果(表示患有癌症)称为正类.将阴性测试结果称为反类。我们不能假设模型永远是完美的，它也会犯错。对于任何应用而言，我们都需要问问自己，这些错误在现实世界中可能有什么后果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f77afc-ce10-4fc9-94f7-e63f008db693",
   "metadata": {},
   "source": [
    "一种可能的错误是健康的患者被诊断为阳性，导致需要进行额外的测试。这给患者带来了一些费用支出和不便(可能还有精神上的苦)。错误的阳性预测叫作**假正例**(false positive)。另一种可能的饼误是患病的人被诊断为阴性，因而不会接受进一步的检查和治疗。未诊断出的癌症可能导致外重㈱健康问题,甚至可能致命。这种类型的错误(错误的阴性预测)叫作**假反例**(false negative)。在统计学中，假正例也叫作第一类错误(type Ⅰ error)， 假反例也叫作第二类错误(type II error)。我也将坚持使用“假正例\"和“假反例\" 的说法，因为它们的含义更加明确,也更好记。在癌症诊断的例子中，显然，我们希望尽量避免假反例，而假正例可以被看作是小麻烦。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf61fd-3f22-4fae-8484-f80d216b708a",
   "metadata": {},
   "source": [
    "虽然这是一个特别极端的例子，但假正例和假反例造成的结果很少相同。在商业应用中. 可以为两种类型的错误分配美元值，即用美元而不是精度来度量某个预测结果的错误。对于选择使用哪种模型的商业决策而言，这种方法研能更有意义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb37338-189a-4df8-a6b2-96ed39a17730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "043122a8-54fc-4e70-bd82-d4e24817b0cf",
   "metadata": {},
   "source": [
    "### 2. 不平衡数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ca5fd-5023-42c8-ab6f-d62e329051cd",
   "metadata": {},
   "source": [
    "如果在两个类别中,一个类别的出现次数比另一个多很多，那么错误类别将发挥重要作用。这在实践中十分常见,一个很好的例子是点击(click-through)预测。其中每个数据点表示一个\"印象\" (impression)，即向用户展示的一个物项。这个物项可能是广告、相关的故事，或者是在社交媒体网站上关注的相关人员。目标是预测用户足否会点击看到的某个特定物项(表示他们感兴趣)。用户对互联网上显示的大多数内容(尤其是广告)都不会点击。你可能需要向用户展示100个广告或文章,他才会找到足够有趣的内容来点击查看，这样就会得到一个数据集，其中每99 个 “未点击\"的数据点，才有一个\"已点击\"的数据点。换句话说，99%的样本属于“未点击\"类别。这种一个类别比另一个类别出现次数多很多的数据集，通常叫作**不平衡数据集**(imbalanced dataset)或者**具有不平衡类别的数据集** (dataset with imbalanced classes)。在实际当中，不平撕数据才是常态，而数据中感兴趣事件的出现次数相同或相似的情况十分罕见。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f24ee-ed4a-4fa6-a837-c6aa843561da",
   "metadata": {},
   "source": [
    "现在假设你在构建一个在点击预测任务中精度达到99%的分类器。这告诉你什么？99%的精度听起来令人印象深刻，但是它并没有考虑类别不平衡。你不必构建机器学习模型,始终预测\"未点击\"就可以得到99%的精度。另一方而，即使是不平衡数据.精度达到99%的模型实际上也是相当不错的。但是,精度无法帮助我们区分不变的\"未点击\"模型与潜在的优秀模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5f1e85-2f12-40c1-b3ff-c9d7234477ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了便于说明,我们将digits数据集中的数字9与其他九个类别加以区分，从而创建一个 9:1的不平衡数据集\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digist = load_digits()\n",
    "y = digist.target == 9\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digist.data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f02920-8a8f-4736-b4c2-76c8293c586a",
   "metadata": {},
   "source": [
    "我们可以使用DummyClassifier来始终预测多数类(这里是\"非9 \")，以查看精度提供的信息量有多么少："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22482b7f-bf70-452a-b5fa-45ceab26d3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels: [False] \n",
      "Test score: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "# 该分类器用作与其他更复杂的分类器进行比较的简单基线\n",
    "import numpy as np\n",
    "# “most_frequent”: 该方法始终返回传递给predict的观察到的参数中最常见的类标签。该方法返回匹配的 one-hot 编码向量\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "pred_most_frequent = dummy_majority.predict(X_test)\n",
    "print(\"Unique predicted labels: {} \".format(np.unique(pred_most_frequent))) \n",
    "print(\"Test score: {:.2f}\".format(dummy_majority.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b6c41-946f-470a-a6ee-ab0c0a29d866",
   "metadata": {},
   "source": [
    "我们得到了接近90%的精度，却没有学到任何内容。这个结果可能看起来相当好，但请思考一会儿。想象一下，有人告拆你他们的模型精度达到90%。你可能会认为他们做得很好。但根据具体问题，也可能是仅预测了一个类别！我们将这个结果与使用一个真实分类器的结果进行对比："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edecad97-dd54-4a95-8a58-2b689c484299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
